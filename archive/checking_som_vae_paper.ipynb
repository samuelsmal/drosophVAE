{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:29:45.947970Z",
     "start_time": "2019-03-22T16:29:45.930038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fix_layout(width:int=95):\n",
    "    from IPython.core.display import display, HTML\n",
    "    display(HTML(\"<style>.container { width:\" + str(width) + \"% !important; }</style>\"))\n",
    "    \n",
    "fix_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:29:47.802256Z",
     "start_time": "2019-03-22T16:29:46.171629Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import shutil\n",
    "from glob import glob\n",
    "from datetime import date\n",
    "\n",
    "import skimage\n",
    "from functools import reduce\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm, trange\n",
    "import sacred\n",
    "from sacred.stflow import LogFileWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:29:47.806866Z",
     "start_time": "2019-03-22T16:29:47.803900Z"
    }
   },
   "outputs": [],
   "source": [
    "from drosoph_vae.somvae_model import SOMVAE\n",
    "from drosoph_vae.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:29:48.076128Z",
     "start_time": "2019-03-22T16:29:47.807984Z"
    }
   },
   "outputs": [],
   "source": [
    "ex = sacred.Experiment(\"replicating\", interactive=True)\n",
    "ex.observers.append(sacred.observers.FileStorageObserver.create(\"./sacred_runs\"))\n",
    "ex.captured_out_filter = sacred.utils.apply_backspaces_and_linefeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:29:48.085612Z",
     "start_time": "2019-03-22T16:29:48.077537Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@ex.config\n",
    "def ex_config():\n",
    "    \"\"\"Sacred configuration for the experiment.\n",
    "    \n",
    "    Params:\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        patience (int): Patience for the early stopping.\n",
    "        batch_size (int): Batch size for the training.\n",
    "        latent_dim (int): Dimensionality of the SOM-VAE's latent space.\n",
    "        som_dim (list): Dimensionality of the self-organizing map.\n",
    "        learning_rate (float): Learning rate for the optimization.\n",
    "        alpha (float): Weight for the commitment loss.\n",
    "        beta (float): Weight for the SOM loss.\n",
    "        gamma (float): Weight for the transition probability loss.\n",
    "        tau (float): Weight for the smoothness loss.\n",
    "        decay_factor (float): Factor for the learning rate decay.\n",
    "        name (string): Name of the experiment.\n",
    "        ex_name (string): Unique name of this particular run.\n",
    "        logdir (path): Directory for the experiment logs.\n",
    "        modelpath (path): Path for the model checkpoints.\n",
    "        interactive (bool): Indicator if there should be an interactive progress bar for the training.\n",
    "        data_set (string): Data set for the training.\n",
    "        save_model (bool): Indicator if the model checkpoints should be kept after training and evaluation.\n",
    "        time_series (bool): Indicator if the model should be trained on linearly interpolated\n",
    "            MNIST time series.\n",
    "        mnist (bool): Indicator if the model is trained on MNIST-like data.\n",
    "    \"\"\"\n",
    "    num_epochs = 10\n",
    "    patience = 100\n",
    "    batch_size = 32\n",
    "    latent_dim = 64\n",
    "    som_dim = [8,8]\n",
    "    learning_rate = 0.0005\n",
    "    alpha = 1.0\n",
    "    beta = 0.9\n",
    "    gamma = 1.8\n",
    "    tau = 1.4\n",
    "    decay_factor = 0.9\n",
    "    name = ex.get_experiment_info()[\"name\"]\n",
    "    ex_name = \"{}_{}_{}-{}_{}_{}\".format(name, latent_dim, som_dim[0], som_dim[1], str(date.today()), uuid.uuid4().hex[:5])\n",
    "    logdir = \"./logs/{}\".format(ex_name)\n",
    "    modelpath = \"./models/{}/{}.ckpt\".format(ex_name, ex_name)\n",
    "    interactive = True\n",
    "    data_set = \"MNIST_data\"\n",
    "    save_model = True \n",
    "    time_series = True \n",
    "    mnist = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:29:48.457003Z",
     "start_time": "2019-03-22T16:29:48.086815Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-7b331fcd731c>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/samuel/.local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/samuel/.local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/samuel/.local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/samuel/.local/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(f\"../data/{ex_config()['data_set']}\")\n",
    "\n",
    "nb_of_data_points = 45000\n",
    "data_train = np.reshape(mnist.train.images, [-1,28,28,1])\n",
    "labels_train = mnist.train.labels\n",
    "data_val = data_train[nb_of_data_points:]\n",
    "labels_val = labels_train[nb_of_data_points:]\n",
    "data_train = data_train[:nb_of_data_points]\n",
    "labels_train = data_train[:nb_of_data_points]\n",
    "\n",
    "@ex.capture\n",
    "def get_data_generator(time_series):\n",
    "    \"\"\"Creates a data generator for the training.\n",
    "    \n",
    "    Args:\n",
    "        time_series (bool): Indicates whether or not we want interpolated MNIST time series or just\n",
    "            normal MNIST batches.\n",
    "    \n",
    "    Returns:\n",
    "        generator: Data generator for the batches.\"\"\"\n",
    "\n",
    "    def batch_generator(mode=\"train\", batch_size=100):\n",
    "        \"\"\"Generator for the data batches.\n",
    "        \n",
    "        Args:\n",
    "            mode (str): Mode in ['train', 'val'] that decides which data set the generator\n",
    "                samples from (default: 'train').\n",
    "            batch_size (int): The size of the batches (default: 100).\n",
    "            \n",
    "        Yields:\n",
    "            np.array: Data batch.\n",
    "        \"\"\"\n",
    "        assert mode in [\"train\", \"val\"], \"The mode should be in {train, val}.\"\n",
    "        if mode==\"train\":\n",
    "            images = data_train.copy()\n",
    "            labels = labels_train.copy()\n",
    "        elif mode==\"val\":\n",
    "            images = data_val.copy()\n",
    "            labels = labels_val.copy()\n",
    "        \n",
    "        while True:\n",
    "            indices = np.random.permutation(np.arange(len(images)))\n",
    "            images = images[indices]\n",
    "            labels = labels[indices]\n",
    "\n",
    "            if time_series:\n",
    "                for i, image in enumerate(images):\n",
    "                    start_image = image\n",
    "                    end_image = images[np.random.choice(np.where(labels == (labels[i] + 1) % 10)[0])]\n",
    "                    interpolation = interpolate_arrays(start_image, end_image, batch_size)\n",
    "                    yield interpolation + np.random.normal(scale=0.01, size=interpolation.shape)\n",
    "            else:\n",
    "                for i in range(len(images)//batch_size):\n",
    "                    yield images[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "    return batch_generator\n",
    "\n",
    "\n",
    "@ex.capture\n",
    "def train_model(model, x, lr_val, num_epochs, patience, batch_size, logdir,\n",
    "        modelpath, learning_rate, interactive, generator):\n",
    "    \"\"\"Trains the SOM-VAE model.\n",
    "    \n",
    "    Args:\n",
    "        model (SOM-VAE): SOM-VAE model to train.\n",
    "        x (tf.Tensor): Input tensor or placeholder.\n",
    "        lr_val (tf.Tensor): Placeholder for the learning rate value.\n",
    "        num_epochs (int): Number of epochs to train.\n",
    "        patience (int): Patience parameter for the early stopping.\n",
    "        batch_size (int): Batch size for the training generator.\n",
    "        logdir (path): Directory for saving the logs.\n",
    "        modelpath (path): Path for saving the model checkpoints.\n",
    "        learning_rate (float): Learning rate for the optimization.\n",
    "        interactive (bool): Indicator if we want to have an interactive\n",
    "            progress bar for training.\n",
    "        generator (generator): Generator for the data batches.\n",
    "    \"\"\"\n",
    "    train_gen = generator(\"train\", batch_size)\n",
    "    val_gen = generator(\"val\", batch_size)\n",
    "\n",
    "    num_batches = len(data_train)//batch_size\n",
    "\n",
    "    saver = tf.train.Saver(keep_checkpoint_every_n_hours=2.)\n",
    "    summaries = tf.summary.merge_all()\n",
    "    \n",
    "    session_config = tf.ConfigProto()\n",
    "    session_config.gpu_options.allow_growth = True\n",
    "\n",
    "    with tf.Session(config=session_config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        patience_count = 0\n",
    "        test_losses = []\n",
    "        with LogFileWriter(ex):\n",
    "            train_writer = tf.summary.FileWriter(logdir+\"/train\", sess.graph)\n",
    "            test_writer = tf.summary.FileWriter(logdir+\"/test\", sess.graph)\n",
    "        print(\"Training...\")\n",
    "        train_step_SOMVAE, train_step_prob = model.optimize\n",
    "        try:\n",
    "            if interactive:\n",
    "                pbar = tqdm(total=num_epochs*(num_batches)) \n",
    "            for epoch in range(num_epochs):\n",
    "                batch_val = next(val_gen)\n",
    "                test_loss, summary = sess.run([model.loss, summaries], feed_dict={x: batch_val})\n",
    "                test_losses.append(test_loss)\n",
    "                test_writer.add_summary(summary, tf.train.global_step(sess, model.global_step))\n",
    "                if test_losses[-1] == min(test_losses):\n",
    "                    saver.save(sess, modelpath, global_step=epoch)\n",
    "                    patience_count = 0\n",
    "                else:\n",
    "                    patience_count += 1\n",
    "                if patience_count >= patience:\n",
    "                    break\n",
    "                for i in range(num_batches):\n",
    "                    batch_data = next(train_gen)\n",
    "                    if i%100 == 0:\n",
    "                        train_loss, summary = sess.run([model.loss, summaries], feed_dict={x: batch_data})\n",
    "                        train_writer.add_summary(summary, tf.train.global_step(sess, model.global_step))\n",
    "                    train_step_SOMVAE.run(feed_dict={x: batch_data, lr_val:learning_rate})\n",
    "                    train_step_prob.run(feed_dict={x: batch_data, lr_val:learning_rate*100})\n",
    "                    if interactive:\n",
    "                        pbar.set_postfix(epoch=epoch, train_loss=train_loss, test_loss=test_loss, refresh=False)\n",
    "                        pbar.update(1)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "        finally:\n",
    "            saver.save(sess, modelpath)\n",
    "            if interactive:\n",
    "                pbar.close()\n",
    "\n",
    "\n",
    "@ex.capture\n",
    "def evaluate_model(model, x, modelpath, batch_size):\n",
    "    \"\"\"Evaluates the performance of the trained model in terms of normalized\n",
    "    mutual information, purity and mean squared error.\n",
    "    \n",
    "    Args:\n",
    "        model (SOM-VAE): Trained SOM-VAE model to evaluate.\n",
    "        x (tf.Tensor): Input tensor or placeholder.\n",
    "        modelpath (path): Path from which to restore the model.\n",
    "        batch_size (int): Batch size for the evaluation.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of evaluation results (NMI, Purity, MSE).\n",
    "    \"\"\"\n",
    "    saver = tf.train.Saver(keep_checkpoint_every_n_hours=2.)\n",
    "\n",
    "    num_batches = len(data_val)//batch_size\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, modelpath)\n",
    "\n",
    "        test_k_all = []\n",
    "        test_rec_all = []\n",
    "        test_mse_all = []\n",
    "        print(\"Evaluation...\")\n",
    "        for i in range(num_batches):\n",
    "            batch_data = data_val[i*batch_size:(i+1)*batch_size]\n",
    "            test_k_all.extend(sess.run(model.k, feed_dict={x: batch_data}))\n",
    "            test_rec = sess.run(model.reconstruction_q, feed_dict={x: batch_data})\n",
    "            test_rec_all.extend(test_rec)\n",
    "            test_mse_all.append(mean_squared_error(test_rec.flatten(), batch_data.flatten()))\n",
    "\n",
    "        test_nmi = compute_NMI(test_k_all, labels_val[:len(test_k_all)])\n",
    "        test_purity = compute_purity(test_k_all, labels_val[:len(test_k_all)])\n",
    "        test_mse = np.mean(test_mse_all)\n",
    "\n",
    "    results = {}\n",
    "    results[\"NMI\"] = test_nmi\n",
    "    results[\"Purity\"] = test_purity\n",
    "    results[\"MSE\"] = test_mse\n",
    "#    results[\"optimization_target\"] = 1 - test_nmi\n",
    "\n",
    "    return results\n",
    " \n",
    "\n",
    "@ex.main\n",
    "def main(latent_dim, som_dim, learning_rate, decay_factor, alpha, beta, gamma, tau, modelpath, save_model, mnist):\n",
    "    \"\"\"Main method to build a model, train it and evaluate it.\n",
    "    \n",
    "    Args:\n",
    "        latent_dim (int): Dimensionality of the SOM-VAE's latent space.\n",
    "        som_dim (list): Dimensionality of the SOM.\n",
    "        learning_rate (float): Learning rate for the training.\n",
    "        decay_factor (float): Factor for the learning rate decay.\n",
    "        alpha (float): Weight for the commitment loss.\n",
    "        beta (float): Weight for the SOM loss.\n",
    "        gamma (float): Weight for the transition probability loss.\n",
    "        tau (float): Weight for the smoothness loss.\n",
    "        modelpath (path): Path for the model checkpoints.\n",
    "        save_model (bool): Indicates if the model should be saved after training and evaluation.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Results of the evaluation (NMI, Purity, MSE).\n",
    "    \"\"\"\n",
    "    # Dimensions for MNIST-like data\n",
    "    input_length = 28\n",
    "    input_channels = 28\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "    #input_length = 19\n",
    "    #input_channels = 3\n",
    "    #x = tf.placeholder(tf.float32, shape=[None, input_length, 1, input_channels])\n",
    "\n",
    "    data_generator = get_data_generator()\n",
    "\n",
    "    lr_val = tf.placeholder_with_default(learning_rate, [])\n",
    "\n",
    "    model = SOMVAE(inputs=x, latent_dim=latent_dim, som_dim=som_dim, learning_rate=lr_val, decay_factor=decay_factor,\n",
    "            input_length=input_length, input_channels=input_channels, alpha=alpha, beta=beta, gamma=gamma,\n",
    "            tau=tau, mnist=mnist)\n",
    "\n",
    "    train_model(model, x, lr_val, generator=data_generator)\n",
    "\n",
    "    result = evaluate_model(model, x)\n",
    "\n",
    "    if not save_model:\n",
    "        shutil.rmtree(os.path.dirname(modelpath))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:08:41.785737Z",
     "start_time": "2019-03-22T16:08:41.783849Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:32:13.949650Z",
     "start_time": "2019-03-22T16:32:13.946504Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:32:13.960789Z",
     "start_time": "2019-03-22T16:32:13.952460Z"
    }
   },
   "outputs": [],
   "source": [
    "#    num_epochs = 10\n",
    "#    patience = 100\n",
    "#    batch_size = 32\n",
    "#    latent_dim = 64\n",
    "#    som_dim = [8,8]\n",
    "#    learning_rate = 0.0005\n",
    "#    alpha = 1.0\n",
    "#    beta = 0.9\n",
    "#    gamma = 1.8\n",
    "#    tau = 1.4\n",
    "#    decay_factor = 0.9\n",
    "#    name = ex.get_experiment_info()[\"name\"]\n",
    "#    ex_name = \"{}_{}_{}-{}_{}_{}\".format(name, latent_dim, som_dim[0], som_dim[1], str(date.today()), uuid.uuid4().hex[:5])\n",
    "#    logdir = \"./logs/{}\".format(ex_name)\n",
    "#    modelpath = \"./models/{}/{}.ckpt\".format(ex_name, ex_name)\n",
    "#    interactive = True\n",
    "#    data_set = \"MNIST_data\"\n",
    "#    save_model = True \n",
    "#    time_series = True \n",
    "#    mnist = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:32:14.654757Z",
     "start_time": "2019-03-22T16:32:13.963476Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - replicating - Running command 'main'\n",
      "INFO - replicating - Started run with ID \"83\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent dims 64, is mnist False\n",
      "shape of h1 (?, 28, 28, 256)\n",
      "shape of h2 (?, 28, 28, 128)\n",
      "dims of ze (?, 28, 28, 64)\n",
      "shape of z_e (?, 28, 28, 64)\n",
      "shape of embeddings (8, 8, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - replicating - Failed after 0:00:00!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 28 and 8 for 'z_dist_flat/SquaredDifference' (op: 'SquaredDifference') with input shapes: [?,1,1,28,28,64], [1,8,8,64].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 28 and 8 for 'z_dist_flat/SquaredDifference' (op: 'SquaredDifference') with input shapes: [?,1,1,28,28,64], [1,8,8,64].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a343f5b8f16d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time_series'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sacred/experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, command_name, config_updates, named_configs, meta_info, options)\u001b[0m\n\u001b[1;32m    207\u001b[0m         run = self._create_run(command_name, config_updates, named_configs,\n\u001b[1;32m    208\u001b[0m                                meta_info, options)\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sacred/run.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_heartbeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_pre_run_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_post_run_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sacred/config/captured_function.py\u001b[0m in \u001b[0;36mcaptured_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# =================== run actual function =================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;31m# =========================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-7b331fcd731c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(latent_dim, som_dim, learning_rate, decay_factor, alpha, beta, gamma, tau, modelpath, save_model, mnist)\u001b[0m\n\u001b[1;32m    209\u001b[0m     model = SOMVAE(inputs=x, latent_dim=latent_dim, som_dim=som_dim, learning_rate=lr_val, decay_factor=decay_factor,\n\u001b[1;32m    210\u001b[0m             \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             tau=tau, mnist=mnist)\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SOM-VAE/drosoph_vae/somvae_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, latent_dim, som_dim, learning_rate, decay_factor, decay_steps, input_length, input_channels, alpha, beta, gamma, tau, mnist)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_e_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dist_flat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SOM-VAE/drosoph_vae/somvae_model.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SOM-VAE/drosoph_vae/somvae_model.py\u001b[0m in \u001b[0;36mz_dist_flat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"shape of z_e {self.z_e.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"shape of embeddings {self.embeddings.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mz_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mz_dist_red\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mz_dist_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dist_red\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msquared_difference\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   9465\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9466\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 9467\u001b[0;31m         \"SquaredDifference\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   9468\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9469\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 28 and 8 for 'z_dist_flat/SquaredDifference' (op: 'SquaredDifference') with input shapes: [?,1,1,28,28,64], [1,8,8,64]."
     ]
    }
   ],
   "source": [
    "res = ex.run(config_updates={'mnist': False, 'num_epochs': 2, 'time_series': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:08:42.281618Z",
     "start_time": "2019-03-22T16:08:39.563Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH=/usr/local/cuda-9.0/bin/:$PATH LD_LIBRARY_PATH=~/Downloads/cudnn-10.0-linux-x64-v7.3.0.29/cuda/lib64/:$LD_LIBRARY_PATH jupyter notebook   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:08:42.282258Z",
     "start_time": "2019-03-22T16:08:39.565Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3 epoch\n",
    "res.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:08:42.282780Z",
     "start_time": "2019-03-22T16:08:39.569Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1 epoch\n",
    "res.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:08:42.283284Z",
     "start_time": "2019-03-22T16:08:39.570Z"
    }
   },
   "outputs": [],
   "source": [
    "ls models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:08:42.283844Z",
     "start_time": "2019-03-22T16:08:39.572Z"
    }
   },
   "outputs": [],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T16:08:42.284418Z",
     "start_time": "2019-03-22T16:08:39.574Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
