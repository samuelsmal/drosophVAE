{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.832Z"
    }
   },
   "outputs": [],
   "source": [
    "from drosoph_vae.settings.config import SetupConfig\n",
    "# adapt according to your machine (0 should be fine, if you have a GPU)\n",
    "if SetupConfig.runs_on_lab_server():\n",
    "    %env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "    %env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0TD5ZrvEMbhZ"
   },
   "source": [
    "# VAE using the reparametrization trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Imports and enabling of eager execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.836Z"
    },
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "import itertools\n",
    "from functional import seq\n",
    "from functools import reduce\n",
    "import warnings\n",
    "import os\n",
    "import traceback\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "from importlib import reload # for debugging and developing, optional\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tfc\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tfkl\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# for the KL-loss explosion problem\n",
    "tf.enable_eager_execution()\n",
    "# we currently handle them ourselves. but with this, it will throw an error before we can apply the fix\n",
    "tfe.seterr(inf_or_nan='raise')\n",
    "\n",
    "# otherwise TF will print soooo many warnings\n",
    "warnings.filterwarnings('ignore', '.*FutureWarning.*np.complexfloating.*')\n",
    "\n",
    "from drosoph_vae.helpers.tensorflow import _TF_DEFAULT_SESSION_CONFIG_\n",
    "import drosoph_vae.helpers.tensorflow as tf_helpers\n",
    "sess = tf.InteractiveSession(config=_TF_DEFAULT_SESSION_CONFIG_)\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "from drosoph_vae import data_loading\n",
    "from drosoph_vae import settings\n",
    "from drosoph_vae import preprocessing\n",
    "from drosoph_vae.helpers import video, plots, misc, jupyter\n",
    "from drosoph_vae.helpers.misc import extract_args, chunks, foldl, if_last\n",
    "from drosoph_vae.helpers.jupyter import display_video\n",
    "from drosoph_vae.helpers.logging import enable_logging\n",
    "from drosoph_vae.helpers.tensorflow import to_tf_data\n",
    "from drosoph_vae.settings import config, skeleton\n",
    "from drosoph_vae.settings import data as SD\n",
    "from drosoph_vae.settings.config import RunConfig, SetupConfig\n",
    "from drosoph_vae.training import vae as vae_training\n",
    "from drosoph_vae.training import supervised as supervised_training\n",
    "from drosoph_vae.losses.normalized_mutual_information import normalized_mutual_information\n",
    "from drosoph_vae.losses.purity import purity\n",
    "from drosoph_vae.models.drosoph_vae_conv import DrosophVAEConv\n",
    "from drosoph_vae.models.drosoph_vae_skip_conv import DrosophVAESkipConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.839Z"
    }
   },
   "outputs": [],
   "source": [
    "jupyter.fix_layout()\n",
    "enable_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T14:02:57.434212Z",
     "start_time": "2019-06-13T14:02:57.431753Z"
    }
   },
   "source": [
    "# Setup, loading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.842Z"
    }
   },
   "outputs": [],
   "source": [
    "setup_cfg = SetupConfig()\n",
    "run_cfg = RunConfig()\n",
    "\n",
    "frame_data, frame_labels, normalisation_factors = data_loading.load_labelled_data(run_config=run_cfg, setup_config=setup_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.846Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_int_value(frame_with_label):\n",
    "    return np.array([l.label.value for l in frame_with_label[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.848Z"
    }
   },
   "outputs": [],
   "source": [
    "if run_cfg['data_type'] == config.DataType.ANGLE_3D:\n",
    "    frame_data, frame_labels, selected_columns, normalisation_factors = preprocessing.preprocess_angle_3d_data(\n",
    "        frame_data, frame_labels, **run_cfg.preprocessing_parameters())\n",
    "if run_cfg['data_type'] == config.DataType.POS_2D:\n",
    "    selected_columns = None\n",
    "    # preprocessing for the pos_2d data happens inside the loading function, yeah... I know ugly\n",
    "    frame_data, frame_labels = preprocessing.preprocess_pos_2d_data(frame_data, frame_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.850Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "n_train_data_points = int(frame_data.shape[0] * run_cfg['train_test_ratio'])\n",
    "\n",
    "X_train = scaler.fit_transform(frame_data[:n_train_data_points])\n",
    "X_test = scaler.transform(frame_data[n_train_data_points:])\n",
    "y_train = to_int_value(frame_labels[:n_train_data_points])\n",
    "y_test = to_int_value(frame_labels[n_train_data_points:])\n",
    "frame_labels_train = frame_labels[:n_train_data_points]\n",
    "frame_labels_test = frame_labels[n_train_data_points:]\n",
    "\n",
    "raw_data = (X_train, X_test, y_train, y_test, frame_labels_train, frame_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.852Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##\n",
    "## debugging overwrite\n",
    "##\n",
    "#    \n",
    "#if run_config['debug']:\n",
    "#    if run_config['d_zero_data']:\n",
    "#        # resetting the scaler to make our life easier down below the pipeline\n",
    "#        _dummy_data_ = np.zeros_like(joint_positions)\n",
    "#    elif run_config['d_sinoid_data']:\n",
    "#        if run_config['data_type'] == _DATA_TYPE_2D_POS_:\n",
    "#            _dummy_data_ = np.zeros_like(joint_positions)\n",
    "#            for frame in range(_dummy_data_.shape[0]):\n",
    "#                for joint in range(_dummy_data_.shape[1]):\n",
    "#                    _dummy_data_[frame, joint, :] = np.sin(2 * np.pi * frame/_dummy_data_.shape[0] + joint / _dummy_data_.shape[1])\n",
    "#                \n",
    "#        else:\n",
    "#            _dummy_data_ = np.array([[np.sin(x) + (offset / joint_positions.shape[1]) \n",
    "#                                      for x in range(len(joint_positions))] \n",
    "#                                     for offset in range(joint_positions.shape[1])]).T.astype(joint_positions.dtype)\n",
    "#    elif run_config['d_sinoid_cluster_data']:\n",
    "#        if run_config['data_type'] == _DATA_TYPE_2D_POS_:\n",
    "#            raise NotImplementedError\n",
    "#        else:\n",
    "#            _dummy_data_ = np.zeros_like(joint_positions)\n",
    "#            _dummy_labels_ = np.zeros(joint_positions.shape[0])\n",
    "#            for c in range(_dummy_data_.shape[1]):\n",
    "#                _dummy_data_[:, c], _dummy_labels_ = dummy_data_complex_sine_like(_dummy_data_.shape[0])\n",
    "#            \n",
    "#    if run_config['data_type'] == _DATA_TYPE_2D_POS_:\n",
    "#        _dummy_data_ = misc.prep_2d_pos_data(_dummy_data_)\n",
    "#        \n",
    "#    if run_config['use_time_series']:\n",
    "#        reshaped_joint_position = scaler.fit_transform(_dummy_data_)\n",
    "#        reshaped_joint_position = misc.to_time_series_np(reshaped_joint_position, sequence_length=run_config['time_series_length'])\n",
    "#        labels = _dummy_labels_[run_config['time_series_length'] - 1:]\n",
    "#    else:\n",
    "#        reshaped_joint_position = _dummy_data_\n",
    "#        labels = _dummy_labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.854Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(plots)\n",
    "#\n",
    "# Making sure that the train/test distributions are not too different from each other\n",
    "#\n",
    "    \n",
    "#if run_cfg['data_type'] == data_loading.DataType.ANGLE_3D:\n",
    "#    fig = plots.plot_3d_angle_data_distribution(X_train[_plt_data_idx_],\n",
    "#                                                X_test[_plt_data_idx_],\n",
    "#                                                selected_columns, \n",
    "#                                                exp_desc=run_cfg.description())\n",
    "#else:\n",
    "#    fig = plots.plot_2d_distribution(data_train[_plt_data_idx_], data_test[_plt_data_idx_], exp_desc=run_config.description())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "# model def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Sources:\n",
    "\n",
    "- https://blog.keras.io/building-autoencoders-in-keras.html (keras autoencoder implementation)\n",
    "- https://medium.com/the-artificial-impostor/notes-understanding-tensorflow-part-3-7f6633fcc7c7 (temporal block)\n",
    "- https://stackoverflow.com/questions/46503816/keras-conv1d-layer-parameters-filters-and-kernel-size (refresher on conv layers)\n",
    "- https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d (refresher on conv layers)\n",
    "- https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_conv/ (for a good overview over diluted causal convolutions)\n",
    "- https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf?gi=c5cb3c007035 (general reference)\n",
    "- https://medium.com/tensorflow/variational-autoencoders-with-tensorflow-probability-layers-d06c658931b7 (VAE with tensorflow probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T13:12:53.469656Z",
     "start_time": "2019-05-10T13:12:53.444967Z"
    },
    "hidden": true
   },
   "source": [
    "### Generative Network\n",
    "This defines the generative model which takes a latent encoding as input, and outputs the parameters for a conditional distribution of the observation, i.e. $p(x|z)$. Additionally, we use a unit Gaussian prior $p(z)$ for the latent variable.\n",
    "\n",
    "### Inference Network\n",
    "This defines an approximate posterior distribution $q(z|x)$, which takes as input an observation and outputs a set of parameters for the conditional distribution of the latent representation. In this example, we simply model this distribution as a diagonal Gaussian. In this case, the inference network outputs the mean and log-variance parameters of a factorized Gaussian (log-variance instead of the variance directly is for numerical stability).\n",
    "\n",
    "### Reparameterization Trick\n",
    "During optimization, we can sample from $q(z|x)$ by first sampling from a unit Gaussian, and then multiplying by the standard deviation and adding the mean. This ensures the gradients could pass through the sample to the inference network parameters.\n",
    "\n",
    "### Network architecture\n",
    "For the inference network, we use two convolutional layers followed by a fully-connected layer. In the generative network, we mirror this architecture by using a fully-connected layer followed by three convolution transpose layers (a.k.a. deconvolutional layers in some contexts). Note, it's common practice to avoid using batch normalization when training VAEs, since the additional stochasticity due to using mini-batches may aggravate instability on top of the stochasticity from sampling.\n",
    "\n",
    "The dilated convolution between signal $f$ and kernel $k$ and dilution factor $l$ is defined as:\n",
    "\n",
    "$$\\left(k \\ast_{l} f\\right)_t = \\sum_{\\tau=-\\infty}^{\\infty} k_\\tau \\cdot f_{t - l\\tau}$$\n",
    "\n",
    "![](./figures/diluted_convolution.png)\n",
    "![](./figures/WaveNet_gif.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "VAEs train by maximizing the evidence lower bound (ELBO) on the marginal log-likelihood:\n",
    "\n",
    "$$\\log p(x) \\ge \\text{ELBO} = \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p(x, z)}{q(z|x)}\\right].$$\n",
    "\n",
    "In practice, we optimize the single sample Monte Carlo estimate of this expectation:\n",
    "\n",
    "$$\\log p(x| z) + \\log p(z) - \\log q(z|x),$$\n",
    "where $z$ is sampled from $q(z|x)$.\n",
    "\n",
    "**Note**: we could also analytically compute the KL term, but here we incorporate all three terms in the Monte Carlo estimator for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.860Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _receptive_field_size_temporal_conv_net_(kernel_size, n_layers):\n",
    "    return 1 + 2 * (kernel_size - 1) * (2 ** n_layers - 1)\n",
    "\n",
    "for k in range(2, 5):\n",
    "    plt.plot([_receptive_field_size_temporal_conv_net_(kernel_size=k, n_layers=n) for n in range(10)], label=f\"kernel size: {k}\")\n",
    "plt.xlabel('number of layers')\n",
    "plt.ylabel('receptive field size')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.862Z"
    }
   },
   "outputs": [],
   "source": [
    "LatentSpaceEncoding = namedtuple('LatentSpaceEncoding', 'mean var')\n",
    "\n",
    "def get_latent_space(model, X):\n",
    "    def _encode_(x):\n",
    "        if hasattr(model, 'encode'):\n",
    "            # normal model\n",
    "            return model.encode(x)\n",
    "        else:\n",
    "            # only encoder/inference net\n",
    "            return model(x)\n",
    "        \n",
    "    if model.__class__ in [DrosophVAEConv, DrosophVAESkipConv]:\n",
    "        return LatentSpaceEncoding(*map(lambda x: x.numpy(), _encode_(X)))\n",
    "    else:\n",
    "        return LatentSpaceEncoding(*map(lambda x: x.numpy()[back_to_single_time], _encode_(X)))\n",
    "    \n",
    "    \n",
    "def _reshape_and_rescale_(X, scaler=scaler, data_type=run_cfg['data_type']):\n",
    "    \"\"\"To be defined in this notebook / function. Basically a larger lambda function\n",
    "    \"\"\"\n",
    "    rescaled = scaler.inverse_transform(X)\n",
    "    if data_type ==  config.DataType.POS_2D:\n",
    "        return rescaled.reshape(-1, 15, 2)\n",
    "    elif data_type ==  config.DataType.ANGLE_3D:\n",
    "        return rescaled\n",
    "    else:\n",
    "        raise ValueError(f\"uh, got something odd: {data_type}\")\n",
    "        \n",
    "def same_experiment_same_fly(exp_0, exp_1):\n",
    "    keys_0 = experiment_key(obj=exp_0).split('-')\n",
    "    keys_1 = experiment_key(obj=exp_1).split('-')\n",
    "    return keys_0[0] == keys_1[0] and keys_0[2] == keys_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.865Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(vae_training)\n",
    "reload(supervised_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.868Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_mutual_info_score, homogeneity_score, silhouette_score, normalized_mutual_info_score\n",
    "from drosoph_vae.settings.data import Experiment, experiment_key\n",
    "\n",
    "def eval_model(training_results, X, X_eval, y, y_frames, run_config, supervised=False, best=False, back_to_single_time=None):\n",
    "    #\n",
    "    # Unsupervised part\n",
    "    #\n",
    "    \n",
    "    model = training_results['model']\n",
    "    exp_desc = run_config.description(short=False)\n",
    "    exp_desc_short = run_config.description()\n",
    "    X_hat_eval = _reshape_and_rescale_(model(X).numpy()[back_to_single_time], data_type=run_config['data_type'])\n",
    "    epochs = len(training_results['train_reports'])\n",
    "    \n",
    "    if supervised:\n",
    "        exp_desc_short = 'supervised_' + exp_desc_short\n",
    "        \n",
    "    if best:\n",
    "        exp_desc_short = 'best_' + exp_desc_short\n",
    "\n",
    "    \n",
    "    #\n",
    "    # Reconstruction plots\n",
    "    #\n",
    "    \n",
    "    if run_config['data_type'] == config.DataType.ANGLE_3D:\n",
    "        plot_recon_path = plots.plot_reconstruction_comparision_angle_3d(X_eval, X_hat_eval, \n",
    "                                                                         epochs=epochs, \n",
    "                                                                         selected_columns=selected_columns,\n",
    "                                                                         run_desc=exp_desc_short)\n",
    "    else:\n",
    "        plot_recon_path = plots.plot_reconstruction_comparision_pos_2d(X_eval, X_hat_eval, \n",
    "                                                                 epochs=epochs, \n",
    "                                                                 run_desc=exp_desc_short)\n",
    "        \n",
    "    #\n",
    "    # Latent plot\n",
    "    #\n",
    "\n",
    "    X_latent = get_latent_space(training_results['model'], X)\n",
    "    X_latent_mean_tsne_proj = TSNE(n_components=2, random_state=42).fit_transform(np.hstack((X_latent.mean, X_latent.var)))\n",
    "\n",
    "    #cluster_assignments = HDBSCAN(min_cluster_size=8).fit_predict(np.hstack((X_latent.mean, X_latent.var)))\n",
    "    # average because of the triplet loss (maybe? kinda makes sense... not?)\n",
    "    cluster_assignments = AgglomerativeClustering(n_clusters=2 * len(list(config.Behavior)), linkage='average')\\\n",
    "        .fit_predict(np.hstack((X_latent.mean, X_latent.var)))\n",
    "                                                                                      \n",
    "    plot_latent_path = plots.plot_latent_space(X_latent,\n",
    "                                         X_latent_mean_tsne_proj,\n",
    "                                         np.array([y.label.name for _, y in y_frames[back_to_single_time]]),\n",
    "                                         cluster_assignments,\n",
    "                                         exp_desc_short,\n",
    "                                         epochs=len(training_results['train_reports']))\n",
    "    \n",
    "    #\n",
    "    # Videos\n",
    "    #\n",
    "    group_videos = list(video.group_video_of_clusters(cluster_assignments,\n",
    "                                                      y_frames[back_to_single_time],\n",
    "                                                      exp_desc_short, \n",
    "                                                      epochs=epochs))\n",
    "    \n",
    "    #nmi = normalized_mutual_information(cluster_assignments, y)\n",
    "    #pur = purity(cluster_assignments, y)\n",
    "    silhouette = silhouette_score(np.hstack((X_latent.mean, X_latent.var)), y[:, -1])\n",
    "    adjusted_mutual_info = adjusted_mutual_info_score(y[:, -1], cluster_assignments)\n",
    "    homogeneity = homogeneity_score(y[:, -1], cluster_assignments)\n",
    "    mutual_info = normalized_mutual_info_score(y[:, -1], cluster_assignments)\n",
    "    \n",
    "    #\n",
    "    # Single video of Hubert, the special fly\n",
    "    # NOTE that the data is altered here\n",
    "    #\n",
    "\n",
    "    hubert = Experiment(**SetupConfig.value('hubert'))\n",
    "    hubert_idx = np.array([same_experiment_same_fly(l, hubert) for l in y_frames[back_to_single_time][:, 1]])\n",
    "\n",
    "    exp_descs = np.array([experiment_key(obj=l) for l in y_frames[back_to_single_time][:, 1]])\n",
    "\n",
    "    X_hat_eval = X_hat_eval[hubert_idx, :]\n",
    "    cluster_assignments = cluster_assignments[hubert_idx]\n",
    "    image_id_with_exp = y_frames[back_to_single_time][hubert_idx]\n",
    "    paths = [video._path_for_image_(image_id, label) for image_id, label in image_id_with_exp]\n",
    "\n",
    "    labels = [l.label.name for l in y_frames[back_to_single_time][hubert_idx, 1]]\n",
    "    \n",
    "    if run_config['data_type'] == config.DataType.POS_2D:\n",
    "        mean_, std_ = normalisation_factors[experiment_key(obj=hubert)]\n",
    "        X_hat_eval = (X_hat_eval *std_) + mean_\n",
    "\n",
    "        X_raw_input = (frame_data.reshape(-1, 15, 2) * std_) + mean_\n",
    "        X_raw_input = X_raw_input[y_frames[back_to_single_time][:, 0].astype(np.int)]\n",
    "        X_hat_eval = np.clip(X_hat_eval, np.min(X_raw_input), np.max(X_raw_input)) # some odd errors otherwise\n",
    "\n",
    "        full_video_path = video.comparision_video_of_reconstruction((X_raw_input, X_hat_eval), \n",
    "                                                                    cluster_assignments,\n",
    "                                                                    image_id_with_exp,\n",
    "                                                                    labels,\n",
    "                                                                    n_train_data_points,\n",
    "                                                                    paths,\n",
    "                                                                    epochs=epochs,\n",
    "                                                                    run_desc=exp_desc_short)\n",
    "    else:\n",
    "        full_video_path = video.comparision_video_of_reconstruction([],\n",
    "                                                                    cluster_assignments,\n",
    "                                                                    image_id_with_exp,\n",
    "                                                                    labels,\n",
    "                                                                    n_train_data_points,\n",
    "                                                                    paths,\n",
    "                                                                    epochs=epochs,\n",
    "                                                                    run_desc=exp_desc_short)\n",
    "        \n",
    "    \n",
    "\n",
    "    return {'latent_projection': X_latent_mean_tsne_proj, \n",
    "            'cluster_assignments': cluster_assignments,\n",
    "            'plot_paths': {'reconstruction': plot_recon_path, 'latent': plot_latent_path},\n",
    "            'video_paths': {'groups': group_videos, 'hubert': full_video_path},\n",
    "            'scores': {\n",
    "                'silhouette': silhouette,\n",
    "                'adjusted_mutual_info': adjusted_mutual_info,\n",
    "                'homogeneity': homogeneity,\n",
    "                'mutual_info': mutual_info\n",
    "            }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.871Z"
    }
   },
   "outputs": [],
   "source": [
    "#if run_cfg['use_time_series']:\n",
    "#    X_train, X_test, y_train, y_test, frame_labels_train, frame_labels_test = [misc.to_time_series_np(x, sequence_length=run_cfg['time_series_length']) \n",
    "#                                        for x in (X_train, X_test, y_train, y_test, frame_labels_train, frame_labels_test)]\n",
    "#\n",
    "#X = np.vstack((X_train, X_test))\n",
    "#y = np.vstack((y_train, y_test))\n",
    "#y_frames = np.vstack((frame_labels_train, frame_labels_test))\n",
    "#\n",
    "#train_dataset = to_tf_data(X_train, y_train, batch_size=run_cfg['batch_size'])\n",
    "#test_dataset = to_tf_data(X_test, y_test, batch_size=run_cfg['batch_size']) \n",
    "#\n",
    "#if run_cfg['use_time_series']:\n",
    "#    back_to_single_time = np.s_[:, -1, :]\n",
    "#else:\n",
    "#    back_to_single_time = np.s_[:]\n",
    "#    \n",
    "#X_eval = _reshape_and_rescale_(X[back_to_single_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.872Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def grid_search(grid_search_params, raw_data):\n",
    "    parameters = product(*grid_search_params.values())\n",
    "    # it's important that it is a generator, tensorflow might complain overwise \n",
    "    # too many writers and such, depends heavily on the computer\n",
    "    cfgs = ((p, config.RunConfig(**dict(zip(grid_search_params.keys(), p)))) for p in parameters)\n",
    "    \n",
    "    vae_n_epochs = SetupConfig.value('training', 'vae', 'n_epochs')\n",
    "    vae_n_epochs_eval = SetupConfig.value('training', 'vae', 'n_epochs_eval')\n",
    "    supervised_n_epochs = SetupConfig.value('training', 'supervised', 'n_epochs')\n",
    "    supervised_n_epochs_eval = SetupConfig.value('training', 'supervised', 'n_epochs_eval')\n",
    "        \n",
    "    for p, cfg in cfgs:\n",
    "        if cfg['use_time_series']:\n",
    "            X_train, X_test, y_train, y_test, frame_labels_train, frame_labels_test = [misc.to_time_series_np(x, sequence_length=cfg['time_series_length']) \n",
    "                                                for x in (raw_data)]\n",
    "\n",
    "        X = np.vstack((X_train, X_test))\n",
    "        y = np.vstack((y_train, y_test))\n",
    "        y_frames = np.vstack((frame_labels_train, frame_labels_test))\n",
    "\n",
    "        train_dataset = to_tf_data(X_train, y_train, batch_size=cfg['batch_size'])\n",
    "        test_dataset = to_tf_data(X_test, y_test, batch_size=cfg['batch_size']) \n",
    "\n",
    "        if cfg['use_time_series']:\n",
    "            back_to_single_time = np.s_[:, -1, :]\n",
    "        else:\n",
    "            back_to_single_time = np.s_[:]\n",
    "\n",
    "        X_eval = _reshape_and_rescale_(X[back_to_single_time])\n",
    "        #\n",
    "        # Unsupervised part\n",
    "        #\n",
    "        \n",
    "        # not the best code, but it needs to run... some results are better than none\n",
    "        try:\n",
    "            # this allows continuous training with a fixed number of epochs. uuuh yeah.\n",
    "            # there is however a side-effect problem here. I am running this on a GPU, `init` and `train` need to be called in order.\n",
    "            # it needs to be init->train, init->train, ... init resets the graph, and I guess this will free up memory\n",
    "            vae_training_args = vae_training.init(input_shape=X_train.shape[1:], run_config=cfg)\n",
    "            # model, losses, ...\n",
    "            vae_training_results = {}\n",
    "            # paths\n",
    "            vae_eval_results = []\n",
    "            for u in range(np.int(vae_n_epochs/ vae_n_epochs_eval)):\n",
    "                vae_training_results = vae_training.train(**{**vae_training_args, **vae_training_results},\n",
    "                                                          train_dataset=train_dataset, \n",
    "                                                          test_dataset=test_dataset,\n",
    "                                                          early_stopping=False,\n",
    "                                                          n_epochs=vae_n_epochs_eval)\n",
    "\n",
    "                vae_eval_results += [eval_model(vae_training_results, X, X_eval, y, y_frames, cfg, back_to_single_time=back_to_single_time)]\n",
    "                #for n, p in vae_eval_results[-1]['plot_paths'].items():\n",
    "                #    tf_helpers.tf_write_image(vae_training_args['test_summary_writer'], n, p, vae_training_results['train_reports'].shape[0])\n",
    "\n",
    "        except Exception:\n",
    "            print(f\"problem with unsupervised {vae_training_args}: {traceback.format_exc()}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            base_mdl = vae_training_results['model'].__class__(**vae_training_args['model_config'])\n",
    "            base_mdl.load_weights(vae_training_args['model_checkpoints_path'])\n",
    "\n",
    "            vae_training_results['model'] = base_mdl\n",
    "            vae_best = eval_model(vae_training_results, X, X_eval, y, y_frames, cfg, best=True, back_to_single_time=back_to_single_time)\n",
    "        except Exception:\n",
    "            print(f\"problem with loading the model: {traceback.format_exc()}\")\n",
    "            continue\n",
    "        #\n",
    "        # Supervised part\n",
    "        # \n",
    "        \n",
    "        try:\n",
    "            # the training process saves the model with the min loss.\n",
    "            \n",
    "            supervised_training_args = supervised_training.init(model=base_mdl.inference_net, run_config=cfg)\n",
    "            supervised_training_results = {}\n",
    "            supervised_eval_results = []\n",
    "            \n",
    "            for u in range(np.int(supervised_n_epochs/ supervised_n_epochs_eval)):\n",
    "                supervised_training_results = supervised_training.train(**{**supervised_training_args, **supervised_training_results},\n",
    "                                                          train_dataset=train_dataset, \n",
    "                                                          test_dataset=test_dataset,\n",
    "                                                          early_stopping=False,\n",
    "                                                          n_epochs=supervised_n_epochs_eval)\n",
    "\n",
    "                base_mdl.inference_net = supervised_training_results['model']\n",
    "                supervised_training_results['model'] = base_mdl \n",
    "                supervised_eval_results += [eval_model(supervised_training_results, X, X_eval, y, y_frames, cfg, supervised=True, back_to_single_time=back_to_single_time)]\n",
    "                supervised_training_results['model'] = base_mdl.inference_net\n",
    "\n",
    "            \n",
    "            # it always saves the full model\n",
    "            base_mdl.load_weights(vae_training_args['model_checkpoints_path'])\n",
    "            base_mdl.inference_net.load_weights(supervised_training_args['model_checkpoints_path'])\n",
    "            supervised_training_results['model'] = base_mdl \n",
    "            supervised_best = eval_model(supervised_training_results, X, X_eval, y, y_frames, cfg, supervised=True, best=True, back_to_single_time=back_to_single_time)\n",
    "        except Exception:\n",
    "            print(f\"problem with supervised {vae_training_args}\\n\\t{supervised_training_args}\\n\\t{traceback.format_exc()}\")\n",
    "            continue\n",
    "        \n",
    "        # too many figures overwise (duh)\n",
    "        plt.close('all')\n",
    "        \n",
    "        res = {'parameters': p,\n",
    "               'vae': {'train_reports': vae_training_results['train_reports'], \n",
    "                       'test_reports':  vae_training_results['test_reports'],\n",
    "                       'model_checkpoints_path': vae_training_args['model_checkpoints_path'],\n",
    "                       'best_model_eval_results': vae_best,\n",
    "                       'eval_results': vae_eval_results},\n",
    "               'supervised': {'train_reports': supervised_training_results['train_reports'],\n",
    "                              'test_reports':  supervised_training_results['test_reports'],\n",
    "                              'model_checkpoints_path': supervised_training_args['model_checkpoints_path'],\n",
    "                              'best_model_eval_results': supervised_best,\n",
    "                              'eval_results': supervised_eval_results}}\n",
    "        \n",
    "        yield res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.874Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class NoParsingFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return not ('input image is not divisible' in record.getMessage())\n",
    "\n",
    "# such a pain in the ass\n",
    "logger= logging.getLogger('imageio_ffmpeg')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addFilter(NoParsingFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.877Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Note that the data will be reused -> Don't adapt the data_type here. \n",
    "# Either include the data loading into the grid-search or make two runs, one for each DataType\n",
    "\n",
    "grid_search_params = {\n",
    "    'model_impl': list(config.ModelType),\n",
    "    'latent_dim': [2, 4, ],\n",
    "    'vae_learning_rate': [1e-4, 1e-6],\n",
    "    'supervised_learning_rate': [1e-5, ],\n",
    "    'time_series_length': [16, 42],\n",
    "}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    started_at = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    if SetupConfig.runs_on_lab_server():\n",
    "        grid_search_results = list(grid_search(grid_search_params, raw_data=raw_data))\n",
    "        misc.dump_results(grid_search_results, f\"grid_search_only_vae_{started_at}\")\n",
    "    else:\n",
    "        grid_search_params = {\n",
    "            'model_impl': [config.ModelType.SKIP_PADD_CONV], # config.ModelType.values(),\n",
    "            'latent_dim': [2, ]\n",
    "        }\n",
    "        grid_search_results = list(grid_search(grid_search_params, raw_data=raw_data))\n",
    "        misc.dump_results(grid_search_results, f\"grid_search_only_vae_{started_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.879Z"
    }
   },
   "outputs": [],
   "source": [
    "len(grid_search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.881Z"
    }
   },
   "outputs": [],
   "source": [
    "_t =[[er['scores'] for er in gsr['vae']['eval_results']] for gsr in grid_search_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.889Z"
    }
   },
   "outputs": [],
   "source": [
    "_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.891Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(_t[0]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.894Z"
    }
   },
   "outputs": [],
   "source": [
    "def _extract_(res):\n",
    "    return (res['train_reports'], res['test_reports'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.897Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_params_as_list = list(product(grid_search_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.899Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_params_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.901Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_data = [parameters, train_reports, test_reports]\n",
    "plot_data = [(res['parameters'], *_extract_(res['vae'])) for res in grid_search_results]\n",
    "losses = ['loss', 'reconstruction', 'kl-divergence']\n",
    "fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(10, 8))\n",
    "for params, train_losses, test_losses in plot_data:\n",
    "    for i, l in enumerate(losses):\n",
    "        axs[i].plot(train_losses[:, i], label=f\"train {l}\")\n",
    "        axs[i].plot(test_losses[:, i], label=f\"test {l}\")\n",
    "        \n",
    "for a in axs:\n",
    "    a.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.903Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_data = [parameters, train_reports, test_reports]\n",
    "plot_data = [(res['parameters'], *_extract_(res['supervised'])) for res in grid_search_results]\n",
    "losses = ['triplet loss']\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 3))\n",
    "for params, train_losses, test_losses in plot_data:\n",
    "    ax.plot(train_losses, label=f\"train triplet loss\")\n",
    "    ax.plot(test_losses, label=f\"test triplet loss\")\n",
    "        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.904Z"
    }
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.906Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_results[0]['vae']['eval_results'][0]['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.909Z"
    }
   },
   "outputs": [],
   "source": [
    "len(grid_search_results[0]['vae']['eval_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.911Z"
    }
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.914Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(tf_helpers)\n",
    "reload(vae_training)\n",
    "reload(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.916Z"
    }
   },
   "outputs": [],
   "source": [
    "#if not SetupConfig.runs_on_lab_server():\n",
    "#    reload(vae_training)\n",
    "#    epochs = 14\n",
    "#    eval_steps = 7\n",
    "#    run_cfg['latent_dim'] = 6\n",
    "#    vae_training_args = vae_training.init(input_shape=X_train.shape[1:], run_config=run_cfg)\n",
    "#    vae_training_results = {}\n",
    "#    eval_results = []\n",
    "#    for u in range(np.int(epochs / eval_steps)):\n",
    "#        vae_training_results = vae_training.train(**{**vae_training_args, **vae_training_results},\n",
    "#                                                  train_dataset=train_dataset, \n",
    "#                                                  test_dataset=test_dataset,\n",
    "#                                                  early_stopping=False,\n",
    "#                                                  n_epochs=eval_steps)\n",
    "#\n",
    "#        eval_results += [eval_model(vae_training_results, X, X_eval, y, y_frames, run_cfg)]\n",
    "#\n",
    "#    eval_results += [eval_model(vae_training_results, X, X_eval, y, y_frames, run_cfg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.918Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(supervised_training)\n",
    "\n",
    "cfg = RunConfig(model_impl=config.ModelType.SKIP_PADD_CONV, latent_dim=1)\n",
    "vae_training_args = vae_training.init(input_shape=X_train.shape[1:], run_config=cfg)\n",
    "vae_training_results = {}\n",
    "vae_eval_results = []\n",
    "epochs = 14\n",
    "eval_steps = 7\n",
    "\n",
    "try:\n",
    "    for u in range(np.int(epochs / eval_steps)):\n",
    "            vae_training_results = vae_training.train(**{**vae_training_args, **vae_training_results},\n",
    "                                                      train_dataset=train_dataset, \n",
    "                                                      test_dataset=test_dataset,\n",
    "                                                      early_stopping=False,\n",
    "                                                      n_epochs=eval_steps)\n",
    "\n",
    "            vae_eval_results += [eval_model(vae_training_results, X, X_eval, y, y_frames, cfg)]\n",
    "        #for n, p in vae_eval_results[-1]['plot_paths'].items():\n",
    "        #    tf_helpers.tf_write_image(vae_training_args['test_summary_writer'], n, p, vae_training_results['train_reports'].shape[0])\n",
    "\n",
    "    vae_eval_results += [eval_model(vae_training_results, X, X_eval, y, y_frames, cfg)]\n",
    "except Exception:\n",
    "    print(f\"problem with {vae_training_args}: {traceback.format_exc()}\")\n",
    "\n",
    "\n",
    "# the training process saves the model with the min loss.\n",
    "base_mdl = vae_training_results['model'].__class__(**vae_training_args['model_config'])\n",
    "base_mdl.load_weights(vae_training_args['model_checkpoints_path'])\n",
    "\n",
    "supervised_training_args = supervised_training.init(model=base_mdl.inference_net, run_config=cfg)\n",
    "supervised_training_results = {}\n",
    "supervised_eval_results = []\n",
    "\n",
    "for u in range(np.int(epochs / eval_steps)):\n",
    "    supervised_training_results = supervised_training.train(**{**supervised_training_args, **supervised_training_results},\n",
    "                                              train_dataset=train_dataset, \n",
    "                                              test_dataset=test_dataset,\n",
    "                                              early_stopping=False,\n",
    "                                              n_epochs=eval_steps)\n",
    "\n",
    "    base_mdl.inference_net = supervised_training_results['model']\n",
    "    supervised_training_results['model'] = base_mdl \n",
    "    supervised_eval_results += [eval_model(supervised_training_results, X, X_eval, y, y_frames, cfg)]\n",
    "    supervised_training_results['model'] = base_mdl.inference_net\n",
    "\n",
    "base_mdl.inference_net = supervised_training_results['model']\n",
    "supervised_training_results['model'] = base_mdl \n",
    "supervised_eval_results += [eval_model(supervised_training_results, X, X_eval, y, y_frames, cfg)]\n",
    "supervised_training_results['model'] = base_mdl.inference_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.920Z"
    }
   },
   "outputs": [],
   "source": [
    "base_mdl.inference_net.layers[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.922Z"
    }
   },
   "outputs": [],
   "source": [
    "X[back_to_single_time].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.925Z"
    }
   },
   "outputs": [],
   "source": [
    "supervised_training_args['model'](X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.927Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.929Z"
    }
   },
   "outputs": [],
   "source": [
    "get_latent_space(supervised_training_results['model'], X)\n",
    "#     17         return LatentSpaceEncoding(*map(lambda x: x.numpy(), model.encode(X)))\n",
    "#     18     else:\n",
    "#---> 19         return LatentSpaceEncoding(*map(lambda x: x.numpy()[back_to_single_time], model.encode(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.931Z"
    }
   },
   "outputs": [],
   "source": [
    "a = tf.zeros((128, 16, 4))\n",
    "b = tf.zeros((128, 16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.933Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.concat((a, b), axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.935Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.937Z"
    }
   },
   "outputs": [],
   "source": [
    "vae_training_results['test_reports'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.940Z"
    }
   },
   "outputs": [],
   "source": [
    "vae_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.942Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_model(vae_training_results, X, X_eval, y, y_frames, run_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.945Z"
    }
   },
   "outputs": [],
   "source": [
    "from drosoph_vae.settings.data import Experiment, experiment_key\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T11:41:23.099387Z",
     "start_time": "2019-06-14T11:40:21.576Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.948Z"
    }
   },
   "outputs": [],
   "source": [
    "base_mdl = vae_training_results['model'].__class__(latent_dim=run_cfg['latent_dim'], \n",
    "                                                   input_shape=X_train.shape[1:],\n",
    "                                                   batch_size=run_cfg['batch_size'])\n",
    "base_mdl.load_weights(vae_training_args['model_checkpoints_path'])\n",
    "\n",
    "X_hat = base_mdl(X).numpy()[back_to_single_time]\n",
    "X_hat = _reshape_and_rescale_(X_hat, data_type=run_cfg['data_type'])\n",
    "\n",
    "cluster_assignments = AgglomerativeClustering(n_clusters=2 * len(list(config.Behavior)), linkage='average')\\\n",
    "        .fit_predict(X_encoded)\n",
    "\n",
    "hubert = Experiment(**SetupConfig.value('hubert'))\n",
    "hubert_idx = np.array([same_experiment_same_fly(l, hubert) for l in y_frames[back_to_single_time][:, 1]])\n",
    "\n",
    "exp_descs = np.array([experiment_key(obj=l) for l in y_frames[back_to_single_time][:, 1]])\n",
    "\n",
    "X_hat = X_hat[hubert_idx, :]\n",
    "cluster_assignments = cluster_assignments[hubert_idx]\n",
    "image_id_with_exp = y_frames[back_to_single_time][hubert_idx]\n",
    "paths = [video._path_for_image_(image_id, label) for image_id, label in image_id_with_exp]\n",
    "\n",
    "labels = [l.label.name for l in y_frames[back_to_single_time][hubert_idx, 1]]\n",
    "mean_, std_ = normalisation_factors[experiment_key(obj=hubert)]\n",
    "X_hat = (X_hat *std_) + mean_\n",
    "\n",
    "_t = frame_data.reshape(-1, 15, 2)\n",
    "X_raw_input = np.vstack((_t[run_cfg['time_series_length'] - 1:n_train_data_points], _t[n_train_data_points + run_cfg['time_series_length'] -1:]))\n",
    "\n",
    "X_raw_input = (X_raw_input * std_) + mean_\n",
    "X_raw_input = X_raw_input[y_frames[back_to_single_time][:, 0].astype(np.int)][hubert_idx]\n",
    "X_hat = np.clip(X_hat, np.min(X_raw_input), np.max(X_raw_input)) # some odd errors otherwise\n",
    "\n",
    "comparision_video_of_reconstruction((X_raw_input, X_hat), cluster_assignments, image_id_with_exp, labels, n_train_data_points, paths, run_desc=run_cfg.description())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.950Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.952Z"
    }
   },
   "outputs": [],
   "source": [
    "display_video('./tryout.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.956Z"
    }
   },
   "outputs": [],
   "source": [
    "X_encoded = np.hstack([t.numpy() for t in base_mdl.encode(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.958Z"
    }
   },
   "outputs": [],
   "source": [
    "SetupConfig.value('fly_image_template')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.960Z"
    }
   },
   "outputs": [],
   "source": [
    "X_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:13:35.775510Z",
     "start_time": "2019-06-13T22:13:35.766999Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.963Z"
    }
   },
   "outputs": [],
   "source": [
    "normalisation_factors.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.969Z"
    }
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T16:37:31.785780Z",
     "start_time": "2019-05-21T16:37:31.782033Z"
    }
   },
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.973Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#if run_cfg['data_type'] == config.DataType.POS_2D:\n",
    "#    fig = plots.plot_comparing_joint_position_with_reconstructed(X_eval,\n",
    "#                                                                 X_hat_eval,\n",
    "#                                                                 X_gen_eval,\n",
    "#                                                                 validation_cut_off=n_train_data_points,\n",
    "#                                                                 exp_desc=exp_desc_short);\n",
    "#else:\n",
    "#    # ncols is an ugly hack... it works on the basis that we have three working angles for each leg\n",
    "#    if run_cfg['use_single_fly']:\n",
    "#        start = 0\n",
    "#        end = len(X_eval)\n",
    "#    else:\n",
    "#        start = 100\n",
    "#        end = 1000\n",
    "#    xticks = np.arange(start, end) / SetupConfig.value('frames_per_second') / 60.\n",
    "#    if run_cfg['debug']:\n",
    "#        _input_data = X[:, :, 0]\n",
    "#        _recon = model(X, apply_sigmoid=False).numpy()[:, :, 0]\n",
    "#        fig, axs = plt.subplots(nrows=_input_data.shape[-1], ncols=1, figsize=(20, 30), sharex=True, sharey=True)\n",
    "#        for i in range(_input_data.shape[-1]):\n",
    "#            _idx_ = np.s_[start:end, i]\n",
    "#            axs[i].plot(xticks, _input_data[_idx_], label='input')\n",
    "#            axs[i].plot(xticks, _recon[_idx_], label='reconstructed')\n",
    "#    else:\n",
    "#        fig, axs = plt.subplots(nrows=X_eval.shape[1], ncols=1, figsize=(20, 30), sharex=True, sharey=True)\n",
    "#        for i, cn in enumerate(SD.get_3d_columns_names(selected_cols)):\n",
    "#            _idx_ = np.s_[start:end, i]\n",
    "#            axs[i].plot(xticks, X_eval[_idx_], label='input')\n",
    "#            axs[i].plot(xticks, reconstructed_data[_idx_], label='reconstructed')\n",
    "#\n",
    "#            axs[i].set_title(cn)\n",
    "#\n",
    "#    axs[-1].set_xlabel('time [min]')\n",
    "#    axs[0].legend(loc='upper left')\n",
    "#    \n",
    "#    #plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#    plt.suptitle(f\"Comparision of selection of data\\n({exp_desc})\")\n",
    "#    \n",
    "#    plt.tight_layout()\n",
    "#    plt.subplots_adjust(top=0.94)\n",
    "#    plt.savefig(f\"./figures/{exp_desc_short}_input_gen_recon_comparision.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.976Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot_latent_space(X_latent, X_latent_mean_tsne_proj, y, run_cfg, epochs=len(vae_training_results['train_reports']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.978Z"
    }
   },
   "outputs": [],
   "source": [
    "#from matplotlib.collections import LineCollection\n",
    "#\n",
    "#def plot_debug(input_data, cluster_assignments, cluster_colors=None):\n",
    "#    _clusters = np.unique(cluster_assignments)\n",
    "#    _colors = sns.color_palette(n_colors=len(_clusters))\n",
    "#    if cluster_colors is None:\n",
    "#        cluster_colors = dict(zip(_clusters, _colors))\n",
    "#        \n",
    "#    lines, colors = zip(*[([(x, input_data[x, 0]) for x in segment], cluster_colors[cluster_id])\n",
    "#                           for cluster_id, segments in video.group_by_cluster(cluster_assignments).items() \n",
    "#                           for segment in segments])\n",
    "#\n",
    "#\n",
    "#    \n",
    "#    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "#    coll = LineCollection(lines, colors=colors)\n",
    "#    #coll.set_array(np.random.random(xy.shape[0]))\n",
    "#\n",
    "#    ax.add_collection(coll)\n",
    "#    ax.autoscale_view()\n",
    "#\n",
    "#    plt.title('Input data and cluster assigment using debug data');\n",
    "#    \n",
    "#if run_cfg['debug']:\n",
    "#    plot_debug(input_data, cluster_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.979Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# use this to add a different shape to the scatter plot\n",
    "# frames_idx_with_labels[:len(frames_of_interest)][frames_of_interest][run_config['time_series_length'] - 1:]['label'].apply(lambda x: x.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.982Z"
    }
   },
   "outputs": [],
   "source": [
    "#cluster_assignments = eval_results[-1]['cluster_assignments']\n",
    "#\n",
    "#group_videos = list(video.group_video_of_clusters(cluster_assignments, y_frames[back_to_single_time], run_cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.984Z"
    }
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.986Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#new_im.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.989Z"
    }
   },
   "outputs": [],
   "source": [
    "def reverse_pos_pipeline(x, normalisation_factors):\n",
    "    \"\"\"TODO This is again pretty shitty... ultra hidden global variable\"\"\"\n",
    "    return x + normalisation_factors[:x.shape[-1]]\n",
    "\n",
    "def video_prep_raw_data(data):\n",
    "    if run_config['use_time_series']:\n",
    "        return reverse_pos_pipeline(scaler.inverse_transform(data[:, -1, :]).reshape(-1, 15, 2))\n",
    "    else:\n",
    "        return reverse_pos_pipeline(scaler.inverse_transform(data.reshape(-1, 30)).reshape(-1, 15, 2))\n",
    "    \n",
    "def video_prep_recon_data(input_data):\n",
    "    return reverse_pos_pipeline(scaler.inverse_transform(model(input_data).numpy()).reshape(-1, 15, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.991Z"
    }
   },
   "outputs": [],
   "source": [
    "if run_config['data_type'] == _DATA_TYPE_2D_POS_:\n",
    "    _positional_data_ = [reverse_pos_pipeline(input_data, normalisation_factors=normalisation_factors), \n",
    "                         reverse_pos_pipeline(reconstructed_data, normalisation_factors=normalisation_factors)]\n",
    "else:\n",
    "    raise NotImplementedError('give me a break')\n",
    "    \n",
    "p = video.comparision_video_of_reconstruction(_positional_data_,\n",
    "                                              images_paths_for_experiments=images_paths_for_experiments, \n",
    "                                              n_train=len(data_train),\n",
    "                                              cluster_assignments=cluster_assignments,\n",
    "                                              as_frames=False,\n",
    "                                              exp_desc=exp_desc_short)\n",
    "\n",
    "display_video(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Super ugly... but necessary...\n",
    "# first there is the time offset due to the slicing\n",
    "# then there is the concatenation of the data...\n",
    "\n",
    "angle_data_pos_to_frame = []\n",
    "\n",
    "for exp_key, data in angle_data_raw: \n",
    "    _exp = SD._experiment_from_key_(exp_key)\n",
    "    \n",
    "    if len(angle_data_pos_to_frame) == 0:\n",
    "        _idx = np.arange(data.shape[0])[run_config['time_series_length'] - 1:]\n",
    "    else:\n",
    "        _idx = np.arange(data.shape[0])# + len(angle_data_pos_to_frame)\n",
    "        \n",
    "    angle_data_pos_to_frame += [(_exp, d) for d in _idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.995Z"
    }
   },
   "outputs": [],
   "source": [
    "        images_paths_for_experiments = settings.data.EXPERIMENTS.map(lambda x: (x, config.positional_data(x)))\\\n",
    "                                               .flat_map(lambda x: [(x[0], config.get_path_for_image(x[0], i)) for i in range(x[1].shape[1])])\\\n",
    "                                               .to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:42.998Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "    frames_idx_with_labels = preprocessing.get_frames_with_idx_and_labels(settings.data.LABELLED_DATA)\n",
    "    frames_of_interest = ~frames_idx_with_labels['label'].isin([settings.data._BehaviorLabel_.REST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.000Z"
    }
   },
   "outputs": [],
   "source": [
    "images_paths_for_experiments = [(exp, config.get_path_for_image(exp, i)) for exp, i in angle_data_pos_to_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.002Z"
    }
   },
   "outputs": [],
   "source": [
    "images_paths_for_experiments[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.004Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(video)\n",
    "from collections import OrderedDict\n",
    "_N_CLUSTER_TO_VIZ_ = 10\n",
    "_t = [(misc.flatten(sequences), cluster_id) for cluster_id, sequences in video.group_by_cluster(cluster_assignments).items()]\n",
    "_t = sorted(_t, key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "cluster_colors = sns.color_palette(n_colors=len(np.unique(cluster_assignments)))\n",
    "\n",
    "cluster_vids = OrderedDict((p[1], video.comparision_video_of_reconstruction(input_data,\n",
    "                                                                            cluster_assignments=cluster_assignments,\n",
    "                                                                            images_paths_for_experiments=images_paths_for_experiments,\n",
    "                                                                            n_train=data_train.shape[0],\n",
    "                                                                            cluster_colors=cluster_colors,\n",
    "                                                                            cluster_id_to_visualize=p[1], \n",
    "                                                                            exp_desc=exp_desc_short,\n",
    "                                                                            is_2d=False))\n",
    "                    for p in _t[:_N_CLUSTER_TO_VIZ_])\n",
    "\n",
    "print('cluster_vids: ', cluster_vids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.008Z"
    }
   },
   "outputs": [],
   "source": [
    "! cat ./drosoph_vae/helpers/video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.011Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "_N_CLUSTER_TO_VIZ_ = 10\n",
    "_t = [(misc.flatten(sequences), cluster_id) for cluster_id, sequences in video.group_by_cluster(cluster_assignments).items()]\n",
    "_t = sorted(_t, key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "cluster_colors = sns.color_palette(n_colors=len(np.unique(cluster_assignments)))\n",
    "\n",
    "cluster_vids = OrderedDict((p[1], video.comparision_video_of_reconstruction(_positional_data_,\n",
    "                                                                      cluster_assignments=cluster_assignments,\n",
    "                                                                      images_paths_for_experiments=images_paths_for_experiments,\n",
    "                                                                      n_train=data_train.shape[0],\n",
    "                                                                      cluster_colors=cluster_colors,\n",
    "                                                                      cluster_id_to_visualize=p[1], exp_desc=exp_desc_short))\n",
    "                    for p in _t[:_N_CLUSTER_TO_VIZ_])\n",
    "\n",
    "print('cluster_vids: ', cluster_vids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.013Z"
    }
   },
   "outputs": [],
   "source": [
    "#c_idx = 0\n",
    "c_idx += 1\n",
    "display_video(list(cluster_vids.values())[c_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.016Z"
    }
   },
   "outputs": [],
   "source": [
    "c_idx = 0\n",
    "#c_idx += 1\n",
    "display_video(list(cluster_vids.values())[c_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.018Z"
    }
   },
   "outputs": [],
   "source": [
    "images_paths_for_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.021Z"
    }
   },
   "outputs": [],
   "source": [
    "len(np.where(cluster_assignments == 11)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.023Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(images_paths_for_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.024Z"
    }
   },
   "outputs": [],
   "source": [
    "for fs, c in _t:\n",
    "    print(f\"cluster {c} has {len(fs)} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.026Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(video)\n",
    "\n",
    "_t = [(misc.flatten(sequences), cluster_id) for cluster_id, sequences in video.group_by_cluster(cluster_assignments).items()]\n",
    "_t = sorted(_t, key=lambda x: len(x[0]), reverse=True)\n",
    "p = video.video_angle(cluster_assignments, images_paths_for_experiments, cluster_id_to_visualize=_t[3][1], exp_desc=exp_desc_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.029Z"
    }
   },
   "outputs": [],
   "source": [
    "display_video(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.034Z"
    }
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T08:18:01.614372Z",
     "start_time": "2019-05-29T08:18:01.610583Z"
    }
   },
   "source": [
    "# Convolution Clarification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the results shown for a Conv1d for all padding options:\n",
    "\n",
    "- valid: only convolutions where the kernel fits inside the input are comptued\n",
    "- causal: input is shifted such that the kernel can only see itself and backwards in time\n",
    "- same: input is padded such that the convolution can also be applied to the border cases\n",
    "\n",
    "kernel sizes of 2 & 3, and dilation rates for 1 to 3.\n",
    "\n",
    "The result is that a valid convolution of kernel size 2 with a dilation factor of 1 compresses the input in a for us good way.\n",
    "The data goes from `[batch_size, n_time_steps, n_channels]` to `[batch_size, n_time_steps - 1, n_filters]` \n",
    "and crops the first time step only. Thus building features by only looking backwards in time,\n",
    "dropping the first-time step. Thus features are build over time and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.038Z"
    }
   },
   "outputs": [],
   "source": [
    "example_data = np.zeros((1, 10, 5), dtype=np.float32)\n",
    "\n",
    "for row in range(example_data.shape[1]):\n",
    "    example_data[:, row, :] = row\n",
    "    \n",
    "example_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.040Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_clarification_kernel(kernel_size):\n",
    "    conv1d_kernel_no_time = np.zeros((kernel_size, example_data.shape[-1], 1), dtype=np.float32)\n",
    "    conv1d_kernel_no_time[0, :, :] = .5\n",
    "    conv1d_kernel_no_time[1, :, :] = 1.\n",
    "    \n",
    "    if kernel_size == 3:\n",
    "        conv1d_kernel_no_time[2, :, :] = 0.1\n",
    "    \n",
    "    return conv1d_kernel_no_time\n",
    "\n",
    "\n",
    "for kernel_size in range(2, 4):\n",
    "    print(f\"data\\n{example_data}\")\n",
    "    print(f\"kernel\\n{conv_clarification_kernel(kernel_size)}\")\n",
    "    for padding in ['valid', 'causal', 'same']:\n",
    "        for dilation in range(1, 4):\n",
    "            example_conv1d = tfkl.Conv1D(filters=1, \n",
    "                                         kernel_size=kernel_size,\n",
    "                                         use_bias=False, \n",
    "                                         padding=padding,\n",
    "                                         dilation_rate=dilation,\n",
    "                                         kernel_initializer=tf.constant_initializer(conv_clarification_kernel(kernel_size)))\n",
    "\n",
    "            conv_res = example_conv1d(example_data).numpy()\n",
    "            print(f\"padding: {padding}, dilation_rate: {dilation}, kernel_size: {kernel_size}, output shape: {conv_res.shape}\\n{conv_res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.043Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_clarification_kernel(kernel_size):\n",
    "    conv1d_kernel_no_time = np.zeros((kernel_size, example_data.shape[-1], example_conv1d_n_filters), dtype=np.float32)\n",
    "    conv1d_kernel_no_time[0, :, :] = .5\n",
    "    conv1d_kernel_no_time[1, :, :] = 1.\n",
    "    \n",
    "    if kernel_size == 3:\n",
    "        conv1d_kernel_no_time[2, :, :] = 0.1\n",
    "    \n",
    "    return conv1d_kernel_no_time\n",
    "\n",
    "kernel_size = 2\n",
    "padding = 'valid'\n",
    "dilation_rate = 1\n",
    "example_conv1d_n_filters = 2\n",
    "\n",
    "print(f\"data\\n{example_data}\")\n",
    "print(f\"kernel\\n{conv_clarification_kernel(kernel_size)}\")\n",
    "example_conv1d = tfkl.Conv1D(filters=example_conv1d_n_filters, \n",
    "                             kernel_size=kernel_size,\n",
    "                             use_bias=False, \n",
    "                             padding=padding,\n",
    "                             dilation_rate=dilation_rate,\n",
    "                             kernel_initializer=tf.constant_initializer(conv_clarification_kernel(kernel_size)))\n",
    "\n",
    "example_max_pooling_layer = tfkl.MaxPool1D()\n",
    "example_dense = tfkl.Dense(2, use_bias=False, kernel_initializer='ones')\n",
    "\n",
    "conv_res = example_conv1d(example_data[:,:2,:]).numpy()\n",
    "#max_pool_res = example_max_pooling_layer(conv_res)\n",
    "#dense_res = example_dense(max_pool_res)\n",
    "print(f\"padding: {padding}, dilation_rate: {dilation_rate}, kernel_size: {kernel_size}, output shape: {conv_res.shape}\")\n",
    "print('conv\\n', conv_res)\n",
    "#print('max pool\\n', max_pool_res.numpy())\n",
    "#print('dense\\n', dense_res.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.044Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.046Z"
    }
   },
   "outputs": [],
   "source": [
    "class Conv1D_Transpose(tfkl.Layer):\n",
    "    def __init__(self, n_filters, kernel_size, batch_size):\n",
    "        super(Conv1D_Transpose, self).__init__()        \n",
    "        self.n_filters = n_filters\n",
    "        self.batch_size = batch_size\n",
    "        self.conv2d_transpose = tfkl.Conv2DTranspose(filters=n_filters, kernel_size=kernel_size, strides=2, padding='valid', kernel_initializer='ones')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, [self.batch_size, 1, *inputs.shape[1:]])\n",
    "        print(x.shape)\n",
    "        x = self.conv2d_transpose(x)\n",
    "        #x = tf.reshape(x, [self.batch_size, -1, self.n_filters])\n",
    "        \n",
    "        return x\n",
    "\n",
    "example_deconv1d = Conv1D_Transpose(n_filters=2, kernel_size=2, batch_size=1)\n",
    "example_deconv1d(conv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.049Z"
    }
   },
   "outputs": [],
   "source": [
    "_ted = example_deconv1d(conv_res)\n",
    "tf.reshape(_ted, _ted.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.052Z"
    }
   },
   "outputs": [],
   "source": [
    "UpsamplingConv(2)(conv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.054Z"
    }
   },
   "outputs": [],
   "source": [
    "tfkl.UpSampling1D(3)(conv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.056Z"
    }
   },
   "outputs": [],
   "source": [
    "class UpsamplingConv(tfkl.Layer):\n",
    "    def __init__(self, n_filters, kernel_size=2):\n",
    "        super(UpsamplingConv, self).__init__()\n",
    "        \n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "    \n",
    "    def call(self, x): \n",
    "        x = tfkl.UpSampling1D(3)(x) # upscale with 3 so that we can again apply `valid` padding and \"reverse\" the encoder\n",
    "        print(x.shape)\n",
    "        # TODO maybe add some fancy flipping of the input\n",
    "        x = tfkl.Conv1D(self.n_filters, self.kernel_size, padding='valid')(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.058Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.060Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T17:55:51.831670Z",
     "start_time": "2019-05-29T17:55:51.802162Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.063Z"
    }
   },
   "outputs": [],
   "source": [
    "example_deconv = tfkl.Conv2DTranspose(1, 2, kernel_initializer='ones')\n",
    "example_deconv(conv_res.reshape(-1, 1, *conv_res.shape[1:])).numpy().reshape(-1, *conv_res.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.065Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.067Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.070Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.072Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.rank(conv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.074Z"
    }
   },
   "outputs": [],
   "source": [
    "paddings = [[r, 0] for r in range(3)]\n",
    "paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.078Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.pad(conv_res, [[0, 0], [0, 1], [0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.080Z"
    }
   },
   "outputs": [],
   "source": [
    "tfc.nn.conv1d_transpose(input=conv_res, filters=np.ones((2, 2, 2), dtype=np.float32), output_shape=[1, 2, 2], strides=1, padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.082Z"
    }
   },
   "outputs": [],
   "source": [
    "_pdc1dt = PaddedConv1dTransposed(n_filters=2)\n",
    "print(conv_res.shape)\n",
    "resc1 = _pdc1dt(conv_res)\n",
    "print(resc1.shape)\n",
    "resc1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.084Z"
    }
   },
   "outputs": [],
   "source": [
    "_pdc1dt(_pdc1dt(resc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-17T06:21:43.087Z"
    }
   },
   "outputs": [],
   "source": [
    "#_t_layer_sizes_generative=[4,6,8,10,12,14,16,18]\n",
    "#_t_layer_sizes_generative=[1] * 6\n",
    "#_t_upsampling_size = [4] * 6 #, 2, 2]\n",
    "#_t_strides = [2] * 6\n",
    "##_t_padding = ['valid', 'valid', 'same']\n",
    "##_t_layer_sizes_generative=[4, 8, 16]\n",
    "#_latent_dim = 2\n",
    "#_t_generative_net = tf.keras.Sequential([tfkl.InputLayer(input_shape=(_latent_dim,)),\n",
    "#                                           tfkl.Lambda(lambda x: tf.reshape(x, [1000, 1, _latent_dim])),\n",
    "#                                           *[TemporalUpsamplingConv(conv_n_filters=fs, \n",
    "#                                                                    upsampling_size=us,\n",
    "#                                                                    conv_strides=s,\n",
    "#                                                                    conv_padding='valid',\n",
    "#                                                                    name=f\"gen_conv_{i}\") for i, (fs, us, s) \n",
    "#                                             in enumerate(zip(_t_layer_sizes_generative,\n",
    "#                                                              _t_upsampling_size,\n",
    "#                                                              _t_strides,\n",
    "#                                                             ))]],\n",
    "#                                          name='generative_net')\n",
    "#\n",
    "#_t_generative_net.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "cvae.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1eb0NOTQapkYs3X0v-zL1x5_LFKgDISnp",
     "timestamp": 1527173385672
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
